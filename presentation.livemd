# State of the art Neural Networks in Elixir

```elixir
Mix.install(
  [
    {:kino_bumblebee, "~> 0.1.0"},
    {:exla, "~> 0.4.1"}
  ],
  config: [nx: [default_backend: EXLA.Backend]]
)
```

## Agenda

1. Text generation - GPT2 - using Bumblebee
2. Text classification - RoBERTa emotions - using Bumblebee
3. Token classification - BERT ner - using Bumblebee
4. Text to image - Stable diffusion - needs GPU - using Bumblebee - play in public
5. Coffee break
6. Image classification - ResNet - using Bumblebee
7. Demo on custom DNN, RNN, LSTM:

* using Axon on NX
* https://www.analyticsvidhya.com/blog/2022/01/the-complete-lstm-tutorial-with-implementation/
* http://colah.github.io/posts/2015-08-Understanding-LSTMs/

1. Some models we cannot run on Beam yet:

* T5 (https://huggingface.co/t5-base)
* Flair (https://huggingface.co/flair)

1. Bonus ChatGPT:

* https://github.com/mgallo/openai.ex
* https://medium.com/@pkp.plus/how-to-connect-to-chat-gpt-api-ce78e4e5f463

Other helpful links:

* https://www.strangeleaflet.com/lets-write-an-elixir-livebook-smart-cell

## Example

<!-- livebook:{"attrs":{"compiler":"exla","max_new_tokens":10,"min_new_tokens":5,"sequence_length":101,"task_id":"text_generation","variant_id":"gpt2"},"chunks":[[0,338],[340,502]],"kind":"Elixir.KinoBumblebee.TaskCell","livebook_object":"smart_cell"} -->

```elixir
{:ok, model_info} = Bumblebee.load_model({:hf, "gpt2"}, log_params_diff: false)
{:ok, tokenizer} = Bumblebee.load_tokenizer({:hf, "gpt2"})

serving =
  Bumblebee.Text.generation(model_info, tokenizer,
    min_new_tokens: 5,
    max_new_tokens: 10,
    compile: [batch_size: 1, sequence_length: 101],
    defn_options: [compiler: EXLA]
  )

text_input = Kino.Input.textarea("Text", default: "Yesterday, I was reading a book and")
form = Kino.Control.form([text: text_input], submit: "Run")
frame = Kino.Frame.new()

form
|> Kino.Control.stream()
|> Kino.listen(fn %{data: %{text: text}} ->
  Kino.Frame.render(frame, Kino.Markdown.new("Running..."))
  %{results: [%{text: generated_text}]} = Nx.Serving.run(serving, text)
  Kino.Frame.render(frame, Kino.Markdown.new(generated_text))
end)

Kino.Layout.grid([form, frame], boxed: true, gap: 16)
```

<!-- livebook:{"branch_parent_index":0} -->

## Text generation using GPT2

```elixir
{:ok, model_info} = Bumblebee.load_model({:hf, "gpt2"}, log_params_diff: false)
{:ok, tokenizer} = Bumblebee.load_tokenizer({:hf, "gpt2"})

gpt2_serving =
  Bumblebee.Text.generation(model_info, tokenizer,
    min_new_tokens: 1,
    max_new_tokens: 50,
    compile: [batch_size: 1, sequence_length: 100],
    defn_options: [compiler: EXLA]
  )
```

```elixir
ui_with_input_run_button_and_result = fn title, text ->
  text_input = Kino.Input.textarea(title, default: text)
  form = Kino.Control.form([text: text_input], submit: "Run")
  frame = Kino.Frame.new()

  form
  |> Kino.Control.stream()
  |> Kino.listen(fn %{data: %{text: text}} ->
    Kino.Frame.render(frame, Kino.Markdown.new("Running..."))
    %{results: [%{text: generated_text}]} = Nx.Serving.run(gpt2_serving, text)
    # hd(String.split(generated_text, "\n"))
    final_text = generated_text
    Kino.Frame.render(frame, Kino.Markdown.new(final_text))
  end)

  [form, frame]
end
```

```elixir
Kino.Layout.grid(
  [
    ui_with_input_run_button_and_result.("Example 1", "The healthiest food is "),
    ui_with_input_run_button_and_result.("Example 2", "What is my dream ?")
  ]
  |> List.flatten(),
  boxed: true,
  gap: 16
)
```
